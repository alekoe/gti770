{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GTI770 - Syst√®mes Intelligents et Apprentissage Machine\n",
    "\n",
    "Alessandro L. Koerich\n",
    "\n",
    "Notebook Jupyter - 10_SVM_UpperLowercaseHandwriting_52Classes\n",
    "\n",
    "July 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import svm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data from file\n",
    "# NIST Train 52 Classes Uppercase + Lowecase Handwritten Characters\n",
    "# 74,880 samples for training\n",
    "# 23,670 samples for validation\n",
    "# 23,941 samples for testing\n",
    "# 108-dimensional feature vectors\n",
    "# 26 classes (A-Z uppercase characters) + 26 classes (a-z lowercase characters) \n",
    "\n",
    "TrainData = np.loadtxt('CSV_Files/Char_UpperLower52.train.csv', delimiter=' ', dtype=np.str)\n",
    "ValidData = np.loadtxt('CSV_Files/Char_UpperLower52.val.csv', delimiter=' ', dtype=np.str)\n",
    "TestData  = np.loadtxt('CSV_Files/Char_UpperLower52.test.csv' , delimiter=' ', dtype=np.str)\n",
    "\n",
    "\n",
    "Xtrain =TrainData[0:74779,0:108].astype(np.float)\n",
    "Ytrain =TrainData[0:74779,108:160].astype(np.int)\n",
    "\n",
    "Xvalid = ValidData[0:23669,0:108].astype(np.float)\n",
    "Yvalid = ValidData[0:23669,108:160].astype(np.int)\n",
    "\n",
    "Xtest  = TestData[0:23940,0:108].astype(np.float)\n",
    "Ytest  = TestData[0:23940,108:160].astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.324913, 0.193763, 0.115073, ..., 0.      , 0.168941, 0.270305],\n",
       "       [0.226327, 0.083919, 0.055946, ..., 0.095636, 0.095636, 0.047818],\n",
       "       [0.181888, 0.186941, 0.19452 , ..., 0.      , 0.108508, 0.018085],\n",
       "       ...,\n",
       "       [0.354641, 0.25424 , 0.143044, ..., 0.045833, 0.068749, 0.      ],\n",
       "       [0.381843, 0.251339, 0.180449, ..., 0.      , 0.205226, 0.      ],\n",
       "       [0.402374, 0.200176, 0.114579, ..., 0.      , 0.156343, 0.      ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "Ytrain2 = argmax(Ytrain, axis=1)\n",
    "Yvalid2 = argmax(Yvalid, axis=1)\n",
    "Ytest2  = argmax(Ytest, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "Xtrain = scaler.fit_transform(Xtrain)\n",
    "Xvalid = scaler.fit_transform(Xvalid)\n",
    "Xtest  = scaler.fit_transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26, 39, 22, ...,  6, 40,  6])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = Ytrain.shape[1]\n",
    "input_dim   = Xtrain.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linearSVM_model():\n",
    "    print(\"SVM with Linear Kernel\\n\")\n",
    "    # create model\n",
    "    model = svm.SVC(C=1.0, cache_size=2000, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovo', degree=3, gamma='auto', kernel='linear',\n",
    "    max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with Linear Kernel\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "# Choose one at each time\n",
    "model = linearSVM_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit the model (TRAIN) \n",
    "model.fit(Xtrain, Ytrain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the model to predict the class of samples\n",
    "# Notice that we are testing the train dataset\n",
    "Ytrain_pred = model.predict(Xtrain)\n",
    "Ytrain_pred\n",
    "\n",
    "Yvalid_pred = model.predict(Xvalid)\n",
    "Yvalid_pred\n",
    "\n",
    "Ytest_pred = model.predict(Xtest)\n",
    "Ytest_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can also predict the probability of each class\n",
    "# train dataset\n",
    "Ytrain_pred_prob = model.predict_proba(Xtrain)\n",
    "Ytrain_pred_prob\n",
    "\n",
    "Yvalid_pred_prob = model.predict_proba(Xvalid)\n",
    "Yvalid_pred_prob\n",
    "\n",
    "Ytest_pred_prob = model.predict_proba(Xtest)\n",
    "Ytest_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Final evaluation of the model (On the Training, Validation or Test dataset)\n",
    "scores = accuracy_score(Ytrain2, Ytrain_pred )\n",
    "print(\"Correct classification rate for the training dataset = \"+str(scores*100)+\"%\")\n",
    "\n",
    "scores2 = accuracy_score(Yvalid2, Yvalid_pred )\n",
    "print(\"Correct classification rate for the validation dataset = \"+str(scores2*100)+\"%\")\n",
    "\n",
    "scores3 = accuracy_score(Ytest2, Ytest_pred )\n",
    "print(\"Correct classification rate for the test dataset = \"+str(scores3*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z', 'a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "print( classification_report(Yvalid2, Yvalid_pred, target_names=target_names))\n",
    "# This works, but we have labels with no predicted samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict and show the confusion matrix (For the Validation dataset)\n",
    "cm = confusion_matrix(Yvalid2, Yvalid_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap, aspect = 'auto')\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize = (20,20))\n",
    "plot_confusion_matrix(cm, classes = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z', 'a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    ", title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize = (28,28))\n",
    "plot_confusion_matrix(cm, classes = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z', 'a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    ", normalize=True, title='Confusion matrix, with normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HYPERPARAMETER OPTIMIZATION\n",
    "\n",
    "OK, but we didn't optimize the parameters of the SVM, such as:\n",
    "\n",
    "1) Kernel\n",
    "\n",
    "2) Cost \n",
    "\n",
    "3) Kernel parameters (gamma)\n",
    "\n",
    "But now, we already have a pre-defined VALIDATION dataset! So, we don't need to split the dataset and use cross-validation.\n",
    "\n",
    "We will use the hypopt Python package (pip install hypopt). It's a professional package created specifically for parameter optimization with a validation set. It works with any scikit-learn model out-of-the-box and can be used with Tensorflow, PyTorch, etc. as well.\n",
    "\n",
    "https://pypi.org/project/hypopt/1.0.0/\n",
    "\n",
    "BE CAREFUL! With such amount of data, it will take tens of minutes to find the best parameters...\n",
    "\n",
    "Actually, it took 1h30min in my iMac 3.2GHz Core i5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the parameters by cross-validation\n",
    "# Assuming you already have train, test, val sets and a model.\n",
    "from hypopt import GridSearch\n",
    "param_grid = [{'kernel': ['rbf'], 'gamma': [1e-2, 1e-3], 'C': [100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [100, 1000]}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Best parameters set found on validation set:\n",
      "\n",
      "Test Score for Optimized Parameters: 0.7293083780472348\n"
     ]
    }
   ],
   "source": [
    "# Grid-search all parameter combinations using a validation set.\n",
    "tuned_model = GridSearch(model = svm.SVC(probability=True, verbose=True), param_grid=param_grid)\n",
    "tuned_model.fit(Xtrain, Ytrain2, Xvalid, Yvalid2)\n",
    "\n",
    "print(\"Best parameters set found on validation set:\")\n",
    "print()\n",
    "print('Test Score for Optimized Parameters:', tuned_model.score(Xvalid, Yvalid2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('We can view the best performing parameters and their scores.')\n",
    "for z in tuned_model.get_param_scores()[:2]:\n",
    "    p, s = z\n",
    "    print(p)\n",
    "    print('Score:', s)\n",
    "print()\n",
    "print('Verify that the lowest scoring parameters make sense.')\n",
    "for z in tuned_model.get_param_scores()[-2:]:\n",
    "    p, s = z\n",
    "    print(p)\n",
    "    print('Score:', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the model to predict the class of samples\n",
    "# Notice that we are testing the train dataset\n",
    "Ytrain_pred = tuned_model.predict(Xtrain)\n",
    "Ytrain_pred\n",
    "\n",
    "Yvalid_pred = tuned_model.predict(Xvalid)\n",
    "Yvalid_pred\n",
    "\n",
    "Ytest_pred = tuned_model.predict(Xtest)\n",
    "Ytest_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can also predict the probability of each class\n",
    "# train dataset\n",
    "Ytrain_pred_prob = tuned_model.predict_proba(Xtrain)\n",
    "Ytrain_pred_prob\n",
    "\n",
    "Yvalid_pred_prob = tuned_model.predict_proba(Xvalid)\n",
    "Yvalid_pred_prob\n",
    "\n",
    "Ytest_pred_prob = tuned_model.predict_proba(Xtest)\n",
    "Ytest_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Final evaluation of the model (On the Training, Validation or Test dataset)\n",
    "scores_tuned = accuracy_score(Ytrain2, Ytrain_pred )\n",
    "print(\"Correct classification rate for the training dataset (first model) = \"+str(scores*100)+\"%\")\n",
    "print(\"Correct classification rate for the training dataset (best model) = \"+str(scores_tuned*100)+\"%\")\n",
    "print()\n",
    "scores_tuned = accuracy_score(Yvalid2, Yvalid_pred )\n",
    "print(\"Correct classification rate for the validation dataset (first model) = \"+str(scores2*100)+\"%\")\n",
    "print(\"Correct classification rate for the validation dataset (best model) = \"+str(scores_tuned*100)+\"%\")\n",
    "print()\n",
    "scores_tuned = accuracy_score(Ytest2, Ytest_pred )\n",
    "print(\"Correct classification rate for the test dataset (first model) = \"+str(scores3*100)+\"%\")\n",
    "print(\"Correct classification rate for the test dataset (best model) = \"+str(scores_tuned*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict and show the confusion matrix (For the Validation dataset)\n",
    "cm = confusion_matrix(Yvalid2, Yvalid_pred )\n",
    "np.set_printoptions(precision=2)\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize = (28,28))\n",
    "plot_confusion_matrix(cm, classes = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z', 'a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    ", title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize = (28,28))\n",
    "plot_confusion_matrix(cm, classes = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z', 'a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    ", normalize=True, title='Confusion matrix, with normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Notebook ended\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
